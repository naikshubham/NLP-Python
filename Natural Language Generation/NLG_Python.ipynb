{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from get_vocabulary import get_vocabulary\n",
    "from get_max_len import get_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input\n",
       "0     John\n",
       "1  William\n",
       "2    James\n",
       "3  Charles\n",
       "4   George"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df = pd.read_csv('data/names.txt', sep=\"\\n\", header=None)\n",
    "names_df.columns=['input']\n",
    "names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess names dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tJohn</td>\n",
       "      <td>John\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\tWilliam</td>\n",
       "      <td>William\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tJames</td>\n",
       "      <td>James\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\tCharles</td>\n",
       "      <td>Charles\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\tGeorge</td>\n",
       "      <td>George\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input     target\n",
       "0     \\tJohn     John\\n\n",
       "1  \\tWilliam  William\\n\n",
       "2    \\tJames    James\\n\n",
       "3  \\tCharles  Charles\\n\n",
       "4   \\tGeorge   George\\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert a tab in front of all the names\n",
    "names_df['input'] = names_df['input'].apply(lambda x : '\\t' + x)\n",
    "\n",
    "# Append a newline at the end of every name\n",
    "# We already appended a tab in front, so the target word should start at index 1\n",
    "names_df['target'] = names_df['input'].apply(lambda x : x[1:len(x)] + '\\n')\n",
    "names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have a DataFrame with two columns containing the names with the start and end tokens appended. The next step is to encode these as numeric values because machine learning models only accept numeric inputs.\n",
    "- create two dictionaries, char_to_idx and idx_to_char, that will contain mappings of characters to integers, e.g., {'\\t': 0, '\\n': 1, 'a': 2, 'b': 3, ...} and the reverse mappings of integers to characters, e.g, {0: '\\t', 1: '\\n', 2: 'a', 3: 'b', ...}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'F': 7, 'G': 8, 'H': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'N': 15, 'O': 16, 'P': 17, 'Q': 18, 'R': 19, 'S': 20, 'T': 21, 'U': 22, 'V': 23, 'W': 24, 'X': 25, 'Y': 26, 'Z': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53}\n",
      "{0: '\\t', 1: '\\n', 2: 'A', 3: 'B', 4: 'C', 5: 'D', 6: 'E', 7: 'F', 8: 'G', 9: 'H', 10: 'I', 11: 'J', 12: 'K', 13: 'L', 14: 'M', 15: 'N', 16: 'O', 17: 'P', 18: 'Q', 19: 'R', 20: 'S', 21: 'T', 22: 'U', 23: 'V', 24: 'W', 25: 'X', 26: 'Y', 27: 'Z', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary\n",
    "vocabulary = get_vocabulary(names_df['input'])\n",
    "\n",
    "# Sort the vocabulary\n",
    "vocabulary_sorted = sorted(vocabulary)\n",
    "\n",
    "# Create the mapping of the vocabulary chars to integers\n",
    "char_to_idx = { char : idx for idx, char in enumerate(vocabulary_sorted) }\n",
    "\n",
    "# Create the mapping of the integers to vocabulary chars\n",
    "idx_to_char = { idx : char for idx, char in enumerate(vocabulary_sorted) }\n",
    "\n",
    "# Print the dictionaries\n",
    "print(char_to_idx)\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V', 'O', 'X', 'p', 'v', 'c', 'L', 'U', 'Q', 'A', 'z', 'Z', 'R', 'g', 'W', 'D', 'j', 'o', 'a', 'y', 'f', 's', 'Y', 'B', 'b', 'd', 'x', 'i', 'h', 'e', 'G', 'I', 'M', 'T', 't', 'K', 'w', 'l', 'm', 'u', 'S', 'E', 'k', 'J', 'P', 'q', 'r', 'F', 'H', '\\t', 'n', '\\n', 'N', 'C'}\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input and target tensors\n",
    "- The input is a list containing all the names in the dataset. So, the first dimension of the input tensor will be the number of names in the dataset. Each name can be thought of as a string having length equal to the length of the longest name and each character in each name is a one-hot encoded vector of size vocabulary. So, the second and third dimensions of the input tensor will be the length of the longest name and the size of the vocabulary. Similar is the case for the target tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258000, 13, 54) (258000, 13, 54) 12\n"
     ]
    }
   ],
   "source": [
    "# Find the length of longest name\n",
    "max_len = get_max_len(names_df['input'])\n",
    "\n",
    "# Initialize the input vector\n",
    "input_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Initialize the target vector\n",
    "target_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')\n",
    "\n",
    "print(input_data.shape, target_data.shape, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have two vectors of appropriate shape which we can fill up with actual data. These vectors can then be fed to the recurrent neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize input and target vectors with values\n",
    "- We created the input and target tensors of appropriate shape containing all zeros. Now, we'll fill these with actual values. The input and target tensors contain all the names in the dataset. Each name can be thought of as a string having length equal to the length of the longest name and each character in each name is a one-hot encoded vector of size vocabulary.\n",
    "- The tensors can be filled-in as follows: `input_data[n_idx, p_idx, char_to_idx[char]]` will be set to 1 whenever the index of the name in the dataset is `n_idx` and it contains the character char in position `p_idx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3-d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((11,12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1,1,10] = 1\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['input']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    input_data[n_idx, c_idx, char_to_idx[char]] = 1\n",
    "\n",
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['target']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    target_data[n_idx, c_idx, char_to_idx[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have the input and target vectors of appropriate shape. We can use these vectors to train the recurrent neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile RNN network\n",
    "- We completed all the data preprocessing steps and have the input and target vectors ready. It is time to build the recurrent neural network. We'll create a small network architecture that will have 50 simple RNN nodes in the first layer followed by a dense layer. The dense layer will generate a probability distribution over the vocabulary for the next character. So, the size of the dense layer will be the same as the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, SimpleRNN, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 13, 50)            5250      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 13, 54)            2754      \n",
      "=================================================================\n",
      "Total params: 8,004\n",
      "Trainable params: 8,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add SimpleRNN layer of 50 units\n",
    "model.add(SimpleRNN(50, input_shape=(max_len+1, len(vocabulary)), return_sequences=True))\n",
    "\n",
    "# Add a TimeDistributed Dense layer of size same as the vocabulary\n",
    "model.add(TimeDistributed(Dense(len(vocabulary), activation='softmax')))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Built and compiled the recurrent neural network model successfully! This model can be trained now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RNN model and start predictions\n",
    "- The output name will be generated character by character. The first character in each name was the start token \\t. We'll feed the start token to the trained model to output a probability distribution over the vocabulary which can be sampled to generate the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2016/2016 [==============================] - 32s 16ms/step - loss: 1.1475\n",
      "Epoch 2/5\n",
      "2016/2016 [==============================] - 15s 7ms/step - loss: 1.0038\n",
      "Epoch 3/5\n",
      "2016/2016 [==============================] - 15s 7ms/step - loss: 0.9622\n",
      "Epoch 4/5\n",
      "2016/2016 [==============================] - 15s 7ms/step - loss: 0.9371\n",
      "Epoch 5/5\n",
      "2016/2016 [==============================] - 15s 7ms/step - loss: 0.9193\n"
     ]
    }
   ],
   "source": [
    "# Fit the model for 5 epochs using a batch size of 128 \n",
    "model.fit(input_data, target_data, batch_size=128, epochs=5)\n",
    "\n",
    "# Create a 3-D zero vector and initialize it with the start token\n",
    "output_seq = np.zeros((1, max_len+1, len(vocabulary)))\n",
    "output_seq[0, 0, char_to_idx['\\t']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(output_seq, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6.44886222e-06, 2.25875177e-04, 7.77585059e-02, 4.79646400e-02,\n",
       "         7.70975202e-02, 6.86370805e-02, 6.54280111e-02, 2.64541302e-02,\n",
       "         4.15442139e-02, 2.86503807e-02, 1.86169166e-02, 7.68048912e-02,\n",
       "         3.57826762e-02, 7.41821826e-02, 9.27876681e-02, 2.50487886e-02,\n",
       "         1.75261572e-02, 2.10567955e-02, 1.74338289e-03, 6.52880743e-02,\n",
       "         4.95353378e-02, 3.43088247e-02, 1.88910135e-03, 2.04495974e-02,\n",
       "         2.21899226e-02, 4.37302078e-04, 2.35137180e-03, 4.66359593e-03,\n",
       "         1.70402011e-04, 4.63752513e-05, 4.88802034e-05, 2.01726834e-05,\n",
       "         3.96271898e-05, 7.40747564e-05, 4.06480176e-05, 1.35272276e-04,\n",
       "         4.36124901e-05, 4.85940518e-06, 4.83805816e-05, 5.77948558e-05,\n",
       "         5.62153728e-05, 6.16438410e-05, 1.60677344e-04, 1.38425574e-04,\n",
       "         1.91800991e-05, 2.40046847e-05, 8.55584512e-05, 5.45861585e-05,\n",
       "         6.26141991e-05, 8.33620470e-06, 3.04365258e-05, 3.50303562e-05,\n",
       "         5.91788739e-05, 4.45097103e-05],\n",
       "        [7.41028498e-06, 2.26060642e-04, 6.26448746e-05, 6.67886707e-05,\n",
       "         7.10734603e-05, 4.54926121e-05, 6.97655487e-05, 5.04823329e-05,\n",
       "         4.35581023e-05, 4.65856065e-05, 4.69305196e-05, 6.60614533e-05,\n",
       "         4.49101062e-05, 5.68301475e-05, 5.12749648e-05, 3.66633722e-05,\n",
       "         4.49610197e-05, 4.51030864e-05, 2.38886842e-05, 6.33952804e-05,\n",
       "         5.56569612e-05, 6.84747793e-05, 3.72492614e-05, 3.95028474e-05,\n",
       "         6.78015713e-05, 1.63309232e-05, 2.57003849e-05, 4.37023627e-05,\n",
       "         3.07068139e-01, 5.13405597e-04, 1.33670832e-03, 1.07074215e-03,\n",
       "         2.06201985e-01, 5.28159508e-05, 2.10206679e-04, 1.10720433e-02,\n",
       "         1.17601171e-01, 2.09490041e-04, 2.59070570e-04, 1.79478973e-02,\n",
       "         6.43431267e-04, 9.80698271e-04, 1.41867146e-01, 1.76478978e-04,\n",
       "         9.03940308e-05, 5.70702925e-02, 9.12242394e-04, 1.04229059e-03,\n",
       "         9.94327366e-02, 7.61931646e-04, 5.17330877e-03, 1.24832542e-04,\n",
       "         2.62410883e-02, 4.15144867e-04],\n",
       "        [2.27510341e-07, 3.77896940e-04, 8.10320853e-06, 8.56372299e-06,\n",
       "         1.07005617e-05, 9.14391603e-06, 1.34886077e-05, 6.00196699e-06,\n",
       "         6.41001907e-06, 9.83187874e-06, 6.14591727e-06, 1.20040550e-05,\n",
       "         6.76270838e-06, 8.35827996e-06, 8.54070731e-06, 5.67608731e-06,\n",
       "         4.40722670e-06, 7.43549663e-06, 2.44699572e-06, 1.38316909e-05,\n",
       "         9.71743520e-06, 9.07530193e-06, 5.03712408e-06, 7.48550019e-06,\n",
       "         4.75021125e-06, 1.00545913e-06, 2.18788614e-06, 3.24626535e-06,\n",
       "         1.94940507e-01, 8.42543226e-03, 7.37914676e-03, 2.06179824e-02,\n",
       "         2.48875752e-01, 1.07668689e-03, 3.47159104e-03, 6.58844947e-04,\n",
       "         1.15245305e-01, 3.11699143e-04, 1.01299922e-03, 3.54584008e-02,\n",
       "         1.06908213e-02, 1.38585716e-02, 1.55371025e-01, 1.33000629e-03,\n",
       "         8.52467201e-05, 5.31003997e-02, 1.02762729e-02, 9.66672413e-03,\n",
       "         2.92431675e-02, 4.45778761e-03, 9.57017858e-03, 5.37552580e-04,\n",
       "         6.21795654e-02, 1.58986577e-03],\n",
       "        [2.53265938e-07, 1.41220549e-02, 3.66862061e-08, 9.02086938e-08,\n",
       "         6.08031883e-08, 4.64576928e-08, 9.23974355e-08, 4.89645764e-08,\n",
       "         4.76328452e-08, 7.76596636e-08, 1.28862339e-07, 7.34467989e-08,\n",
       "         5.66236942e-08, 5.40907159e-08, 4.18872936e-08, 5.38620633e-08,\n",
       "         3.41130928e-08, 6.80257202e-08, 6.59856241e-08, 5.93301479e-08,\n",
       "         5.62815039e-08, 4.14989856e-08, 1.22251549e-07, 6.32326689e-08,\n",
       "         7.58904903e-08, 1.12141542e-07, 7.56368834e-08, 1.19286881e-07,\n",
       "         8.76228288e-02, 5.29969623e-03, 6.76095439e-03, 2.63059940e-02,\n",
       "         2.28750244e-01, 3.14331404e-03, 6.05106540e-03, 2.49383069e-04,\n",
       "         1.49724856e-01, 7.03436730e-04, 1.27124619e-02, 1.80502087e-02,\n",
       "         1.09991804e-02, 3.40202004e-02, 7.48175010e-02, 1.46889966e-03,\n",
       "         1.14052219e-03, 2.12856412e-01, 2.60446183e-02, 3.56327742e-02,\n",
       "         9.30005033e-03, 3.21761332e-03, 7.14513287e-03, 1.99657967e-04,\n",
       "         2.18755137e-02, 1.78332324e-03],\n",
       "        [3.47354110e-08, 1.31808907e-01, 9.99657459e-08, 8.50181721e-08,\n",
       "         1.39053924e-07, 1.96204468e-07, 3.89045795e-07, 8.07622484e-08,\n",
       "         1.02313720e-07, 9.58413509e-08, 1.71092111e-07, 1.54594773e-07,\n",
       "         1.53278535e-07, 1.63485637e-07, 1.06136291e-07, 9.68598144e-08,\n",
       "         5.35450688e-08, 1.04421460e-07, 6.63739428e-08, 2.90831053e-07,\n",
       "         2.47121875e-07, 1.05574195e-07, 2.07804376e-07, 1.10006155e-07,\n",
       "         8.36356122e-08, 2.70105645e-08, 3.27052341e-08, 1.31565244e-07,\n",
       "         7.97811002e-02, 3.47895734e-02, 2.26589781e-03, 1.10991420e-02,\n",
       "         2.07894996e-01, 8.96549260e-04, 5.53595135e-04, 1.78015779e-03,\n",
       "         1.82075933e-01, 3.11537769e-05, 3.52522853e-04, 5.10370694e-02,\n",
       "         2.87277028e-02, 1.94862224e-02, 3.27582806e-02, 1.40746939e-03,\n",
       "         6.90330926e-05, 6.53716922e-02, 5.55012040e-02, 2.76795011e-02,\n",
       "         9.29553341e-03, 4.04496037e-04, 5.88374387e-04, 4.97319888e-06,\n",
       "         5.32156192e-02, 1.11997128e-03],\n",
       "        [8.91626151e-09, 4.56987023e-01, 7.79349918e-08, 9.00958028e-08,\n",
       "         1.03103140e-07, 1.46387691e-07, 1.83083245e-07, 3.65403920e-08,\n",
       "         1.33052566e-07, 6.35838830e-08, 7.03053402e-08, 1.01284009e-07,\n",
       "         1.36860422e-07, 1.43636413e-07, 2.01098132e-07, 6.49423626e-08,\n",
       "         4.11814547e-08, 5.08562863e-08, 1.38634020e-08, 7.08541847e-08,\n",
       "         9.62008073e-08, 5.99175252e-08, 6.32134913e-08, 3.52676608e-08,\n",
       "         5.21580255e-08, 9.22632015e-09, 1.24128601e-08, 3.62432395e-08,\n",
       "         1.08408049e-01, 1.62656201e-04, 1.11698499e-03, 5.76540641e-03,\n",
       "         1.18735135e-01, 1.32807458e-04, 5.30500314e-04, 7.28221936e-03,\n",
       "         6.95595294e-02, 7.74679393e-06, 5.65802729e-05, 5.44033526e-03,\n",
       "         7.46222446e-04, 8.22385177e-02, 2.26314850e-02, 4.70929772e-05,\n",
       "         1.92384650e-05, 7.12204650e-02, 1.05632944e-02, 9.72275808e-03,\n",
       "         1.44009094e-03, 7.01184617e-04, 2.14263215e-04, 1.37189460e-07,\n",
       "         2.61164308e-02, 1.51634857e-04],\n",
       "        [5.68310066e-09, 7.19476938e-01, 5.82334820e-08, 5.97412466e-08,\n",
       "         8.17621171e-08, 1.74810864e-07, 2.21650907e-07, 4.67269849e-08,\n",
       "         9.86694673e-08, 3.90228756e-08, 7.03432690e-08, 9.35203488e-08,\n",
       "         1.09031902e-07, 1.03450098e-07, 1.43915400e-07, 3.70041597e-08,\n",
       "         5.52611077e-08, 3.63096184e-08, 3.05067331e-08, 1.63054651e-07,\n",
       "         1.51828914e-07, 8.58633058e-08, 5.43550946e-08, 4.97858004e-08,\n",
       "         5.22095149e-08, 5.21449994e-09, 1.00746655e-08, 8.22761734e-08,\n",
       "         2.68688425e-02, 1.54110865e-04, 1.84738630e-04, 1.84752804e-03,\n",
       "         6.32860214e-02, 6.33587188e-05, 1.20173427e-04, 5.10145583e-05,\n",
       "         4.00408171e-02, 3.60045391e-07, 3.76454000e-06, 1.34519013e-02,\n",
       "         1.36013853e-03, 2.01238580e-02, 1.60337444e-02, 3.84842948e-04,\n",
       "         7.62993295e-06, 2.63535101e-02, 2.51494790e-03, 5.52819110e-04,\n",
       "         5.67681296e-03, 1.15572075e-04, 1.00530335e-03, 2.26650712e-07,\n",
       "         6.02088384e-02, 1.10047462e-04],\n",
       "        [1.04278042e-09, 9.45319593e-01, 4.33545004e-08, 1.64754557e-08,\n",
       "         2.50104808e-08, 4.73659654e-08, 5.61523201e-08, 1.46194026e-08,\n",
       "         4.13389429e-08, 1.11481482e-08, 1.69259735e-08, 1.87418472e-08,\n",
       "         3.83587846e-08, 4.72449670e-08, 3.61781964e-08, 1.24785720e-08,\n",
       "         1.87420977e-08, 1.47529065e-08, 3.19237792e-09, 3.83682952e-08,\n",
       "         2.19837784e-08, 2.45033540e-08, 1.46246473e-08, 7.65741515e-09,\n",
       "         2.23022187e-08, 6.07747408e-10, 2.59135846e-09, 1.04203126e-08,\n",
       "         1.58450883e-02, 2.87846387e-06, 2.63266760e-04, 2.81093438e-04,\n",
       "         4.23187530e-03, 4.08577023e-07, 1.09598914e-05, 2.08851183e-03,\n",
       "         2.35244911e-03, 9.23295147e-07, 8.34373168e-06, 2.40058056e-04,\n",
       "         1.95166467e-05, 1.20186703e-02, 8.97176098e-03, 1.83546172e-06,\n",
       "         2.73620458e-06, 2.56778294e-04, 1.92865764e-03, 1.68803870e-03,\n",
       "         1.43458787e-03, 6.01808642e-06, 5.69630756e-05, 5.31520854e-08,\n",
       "         2.82605551e-03, 1.43166370e-04],\n",
       "        [2.10503064e-08, 9.40471530e-01, 8.32864977e-09, 4.49102444e-09,\n",
       "         6.55396182e-09, 2.17459952e-08, 1.65226055e-08, 8.71218386e-09,\n",
       "         1.67867036e-08, 7.38943617e-09, 1.39497267e-08, 1.01064250e-08,\n",
       "         1.28734152e-08, 1.76042327e-08, 1.21101200e-08, 7.33149763e-09,\n",
       "         8.88720209e-09, 1.00005773e-08, 7.08744130e-09, 1.58839377e-08,\n",
       "         1.10396474e-08, 9.56269552e-09, 2.24804939e-08, 6.08633144e-09,\n",
       "         1.42985233e-08, 4.50208848e-09, 5.72829872e-09, 3.05896570e-08,\n",
       "         3.95853026e-03, 4.02847309e-06, 9.86228042e-05, 1.02201862e-04,\n",
       "         1.05269626e-02, 4.64588857e-06, 1.62184824e-05, 1.43845327e-05,\n",
       "         1.22862146e-03, 1.31541776e-06, 2.71703811e-05, 1.32523666e-04,\n",
       "         1.28236616e-05, 3.87244783e-02, 1.42242655e-03, 1.95939028e-05,\n",
       "         3.74117953e-05, 3.64923559e-04, 1.10835070e-03, 3.96690477e-04,\n",
       "         7.01973098e-04, 7.11297980e-06, 2.10211801e-04, 1.28776705e-07,\n",
       "         3.86329048e-04, 2.10017497e-05],\n",
       "        [2.95668734e-09, 9.96211648e-01, 4.23014264e-08, 1.35975453e-08,\n",
       "         2.12236859e-08, 6.95921827e-08, 4.56884379e-08, 1.75002697e-08,\n",
       "         6.19349478e-08, 9.68785763e-09, 3.81507554e-08, 1.88824991e-08,\n",
       "         2.16736815e-08, 6.22797813e-08, 5.19888914e-08, 2.14513918e-08,\n",
       "         2.11337685e-08, 1.80192856e-08, 8.25215896e-09, 3.81357665e-08,\n",
       "         3.92096062e-08, 3.12624095e-08, 2.46930831e-08, 1.15099494e-08,\n",
       "         2.75723053e-08, 1.95597027e-09, 6.27100638e-09, 3.14063264e-08,\n",
       "         6.40630431e-04, 1.50629000e-06, 5.54104117e-05, 1.52597058e-05,\n",
       "         5.06058605e-05, 2.50303174e-07, 6.67818722e-06, 1.41309356e-04,\n",
       "         4.28951753e-05, 1.17723033e-07, 1.11325144e-05, 9.30649257e-05,\n",
       "         6.81771326e-06, 6.57462631e-04, 1.12667447e-03, 1.32935850e-06,\n",
       "         4.60839919e-06, 7.92745777e-06, 3.72682262e-04, 4.64869809e-04,\n",
       "         1.67396047e-05, 3.19759579e-06, 2.95796667e-06, 1.30816709e-08,\n",
       "         4.91171304e-05, 1.48908994e-05],\n",
       "        [2.94802103e-08, 9.84330714e-01, 9.92569227e-09, 3.36397710e-09,\n",
       "         7.70865594e-09, 2.48617376e-08, 9.86215376e-09, 1.07093916e-08,\n",
       "         2.75779168e-08, 7.34649452e-09, 1.68443499e-08, 1.28420821e-08,\n",
       "         1.17715491e-08, 2.61074575e-08, 1.21812009e-08, 1.04809414e-08,\n",
       "         8.26142976e-09, 1.09533449e-08, 5.53908253e-09, 1.15979599e-08,\n",
       "         1.42396637e-08, 9.45672074e-09, 2.24215437e-08, 4.61020067e-09,\n",
       "         1.78459327e-08, 6.69371802e-09, 8.44954062e-09, 3.59934305e-08,\n",
       "         5.30225737e-03, 1.64803009e-06, 4.59261755e-05, 4.38305833e-05,\n",
       "         2.93792295e-03, 3.05643226e-07, 9.86515988e-06, 1.51267377e-04,\n",
       "         1.94789129e-04, 3.49823324e-07, 2.09673835e-05, 3.39824415e-04,\n",
       "         3.61293837e-06, 4.09896113e-03, 6.06376154e-04, 4.59773810e-06,\n",
       "         1.00614980e-05, 4.47711529e-04, 4.72803455e-04, 8.08500394e-04,\n",
       "         1.24326907e-04, 1.17424986e-06, 1.19936594e-05, 2.65720566e-08,\n",
       "         1.48047848e-05, 1.53483325e-05],\n",
       "        [9.83659998e-09, 9.94606316e-01, 7.78535849e-08, 4.61872958e-08,\n",
       "         6.57224319e-08, 1.72254275e-07, 1.04934841e-07, 4.88282836e-08,\n",
       "         1.39104131e-07, 2.24497754e-08, 7.02406098e-08, 5.52060371e-08,\n",
       "         3.81910468e-08, 2.14345704e-07, 1.88952797e-07, 7.05122929e-08,\n",
       "         3.74618701e-08, 4.63524152e-08, 2.56926889e-08, 8.88266740e-08,\n",
       "         1.29038085e-07, 1.09990481e-07, 4.74209614e-08, 2.46522109e-08,\n",
       "         7.28842053e-08, 7.40271267e-09, 1.78060411e-08, 6.78849048e-08,\n",
       "         8.50122597e-05, 3.04566652e-06, 5.24813877e-05, 3.23607019e-05,\n",
       "         3.19787296e-06, 1.15970920e-06, 3.86489592e-05, 4.12094989e-04,\n",
       "         1.38559853e-05, 1.82329330e-07, 8.92240951e-06, 3.23728455e-04,\n",
       "         1.10614652e-04, 1.86925358e-03, 2.65431503e-04, 7.15761371e-06,\n",
       "         3.63065919e-06, 4.73174478e-05, 4.87639045e-04, 1.57430430e-03,\n",
       "         7.66969697e-06, 2.41312973e-05, 1.92029165e-06, 2.58085517e-08,\n",
       "         7.84351778e-06, 9.91234629e-06],\n",
       "        [5.96897642e-09, 9.90282774e-01, 3.79139253e-09, 1.92760230e-09,\n",
       "         3.54316532e-09, 1.10744462e-08, 4.31111680e-09, 4.55039961e-09,\n",
       "         8.42711589e-09, 2.62876654e-09, 5.97614136e-09, 6.23789553e-09,\n",
       "         4.80613416e-09, 1.73326278e-08, 5.34996358e-09, 4.72350647e-09,\n",
       "         2.59393640e-09, 5.03424902e-09, 1.83262483e-09, 8.40829895e-09,\n",
       "         7.28740179e-09, 3.87471921e-09, 6.53062804e-09, 1.92906224e-09,\n",
       "         7.34164418e-09, 1.77568527e-09, 2.85068102e-09, 1.14313927e-08,\n",
       "         2.85153394e-03, 2.43229374e-06, 2.13618187e-05, 2.03370855e-05,\n",
       "         1.49187935e-03, 3.49769437e-07, 1.05605359e-05, 3.12829885e-04,\n",
       "         1.21375480e-04, 2.11391978e-07, 7.80188839e-06, 3.80519399e-04,\n",
       "         1.03587763e-05, 7.91478844e-04, 4.57560905e-04, 6.14041619e-06,\n",
       "         5.70490329e-06, 4.85304277e-04, 4.92274645e-04, 2.11737119e-03,\n",
       "         1.16922412e-04, 8.25708582e-07, 2.26052521e-06, 1.21033326e-08,\n",
       "         5.02579996e-06, 4.83738722e-06]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probabilities for the first character\n",
    "probs = model.predict_proba(output_seq, verbose=0)[:,1,:] # 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4102850e-06, 2.2606064e-04, 6.2644875e-05, 6.6788671e-05,\n",
       "        7.1073460e-05, 4.5492612e-05, 6.9765549e-05, 5.0482333e-05,\n",
       "        4.3558102e-05, 4.6585606e-05, 4.6930520e-05, 6.6061453e-05,\n",
       "        4.4910106e-05, 5.6830148e-05, 5.1274965e-05, 3.6663372e-05,\n",
       "        4.4961020e-05, 4.5103086e-05, 2.3888684e-05, 6.3395280e-05,\n",
       "        5.5656961e-05, 6.8474779e-05, 3.7249261e-05, 3.9502847e-05,\n",
       "        6.7801571e-05, 1.6330923e-05, 2.5700385e-05, 4.3702363e-05,\n",
       "        3.0706814e-01, 5.1340560e-04, 1.3367083e-03, 1.0707421e-03,\n",
       "        2.0620199e-01, 5.2815951e-05, 2.1020668e-04, 1.1072043e-02,\n",
       "        1.1760117e-01, 2.0949004e-04, 2.5907057e-04, 1.7947897e-02,\n",
       "        6.4343127e-04, 9.8069827e-04, 1.4186715e-01, 1.7647898e-04,\n",
       "        9.0394031e-05, 5.7070293e-02, 9.1224239e-04, 1.0422906e-03,\n",
       "        9.9432737e-02, 7.6193165e-04, 5.1733088e-03, 1.2483254e-04,\n",
       "        2.6241088e-02, 4.1514487e-04]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy.random.choice\n",
    "\n",
    "```\n",
    " numpy.random.choice(a, size=None, replace=True, p=None)Â¶\n",
    " \n",
    "Parameters\n",
    "\n",
    "    a :1-D array-like or int\n",
    "        If an ndarray, a random sample is generated from its elements. If an int, the random sample is generated as if a were np.arange(a) sizeint or tuple of ints, optional\n",
    "\n",
    "Output shape : If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. Default is None, in which case a single value is returned.\n",
    "    replace: boolean, optional\n",
    "\n",
    "        Whether the sample is with or without replacement\n",
    "    p : 1-D array-like, optional\n",
    "\n",
    "        The probabilities associated with each entry in a. If not given the sample assumes a uniform distribution over all entries in a.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    }
   ],
   "source": [
    "# Sample vocabulary to get first character\n",
    "first_char = np.random.choice(sorted(vocabulary), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "\n",
    "# Print the character genaerated\n",
    "print(first_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we know how to train the RNN model and generate the first character given the seed character as input. We'll use this character to generate the next character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate baby names\n",
    "- generate the second character by feeding the start token and the generated first character again to the trained network. We'll also be generating full names starting from the start token and repeating this process until the end token is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "# Print the first character which we got last time\n",
    "print(first_char)\n",
    "\n",
    "# Update the vector to contain first the character\n",
    "output_seq[0, 1, char_to_idx[first_char]] = 1\n",
    "\n",
    "# Get the probabilities for the second character\n",
    "probs = model.predict_proba(output_seq, verbose=0)[:,2,:]\n",
    "\n",
    "# Sample vocabulary to get second character\n",
    "second_char = np.random.choice(sorted(vocabulary), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "\n",
    "# Print the second character\n",
    "print(second_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_baby_names(n):\n",
    "    for i in range(0,n):\n",
    "        stop=False\n",
    "        counter=1\n",
    "        name=''\n",
    "        # initialize first char of output seq\n",
    "        output_seq=np.zeros((1,max_len+1,len(vocabulary)))\n",
    "        output_seq[0,0,char_to_idx['\\t']] = 1\n",
    "        # continue until a newline is generated or max no of chars reached\n",
    "        while stop==False and counter<10:\n",
    "            # get prob distribution for next char\n",
    "            probs = model.predict_proba(output_seq, verbose=0)[:,counter-1,:]\n",
    "            # sample vocab to get most probable next char\n",
    "            c = np.random.choice(sorted(list(vocabulary)), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "            if c=='\\n':\n",
    "                stop=True\n",
    "            else:\n",
    "                name = name + c\n",
    "                output_seq[0,counter,char_to_idx[c]] = 1\n",
    "                counter+= 1\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rudon\n",
      "Ungarkey\n",
      "Lyndo\n",
      "Loley\n",
      "Edsi\n"
     ]
    }
   ],
   "source": [
    "generate_baby_names(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
